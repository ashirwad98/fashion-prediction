{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5fd2be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from PIL import Image\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c1458e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATHS = {\n",
    "    \"real\": [\"Celeb-real\", \"YouTube-real\"],\n",
    "    \"fake\": [\"Celeb-Youtube-fake\"]\n",
    "}\n",
    "TEST_PATH = \"test\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a58c05ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames_from_video(video_path, frame_rate=30):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if count % frame_rate == 0:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            pil_img = Image.fromarray(frame)\n",
    "            frames.append(pil_img)\n",
    "        count += 1\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    data, labels = [], []\n",
    "    for label, categories in enumerate([\"real\", \"fake\"]):\n",
    "        for folder in DATASET_PATHS[categories]:\n",
    "            folder_path = os.path.join(folder)\n",
    "            for filename in os.listdir(folder_path):\n",
    "                if filename.endswith(('.mp4', '.avi', '.mov')):\n",
    "                    video_path = os.path.join(folder_path, filename)\n",
    "                    frames = extract_frames_from_video(video_path)\n",
    "                    for frame in frames[:5]:  # use only first 5 frames\n",
    "                        try:\n",
    "                            tensor = transform(frame)\n",
    "                            data.append(tensor)\n",
    "                            labels.append(label)\n",
    "                        except:\n",
    "                            continue\n",
    "    return torch.stack(data), torch.tensor(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a7b3ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing videos...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading and preprocessing videos...\")\n",
    "X, y = load_data()\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cde8c513",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "test_dataset = TensorDataset(test_x, test_y)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b5b25ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASHIRWAD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASHIRWAD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec616840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/5, Loss: 0.0176\n",
      "Epoch 2/5, Loss: 0.0086\n",
      "Epoch 3/5, Loss: 0.0050\n",
      "Epoch 4/5, Loss: 0.0038\n",
      "Epoch 5/5, Loss: 0.0034\n"
     ]
    }
   ],
   "source": [
    "print(\"Training model...\")\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_x, batch_y in zip(train_x.split(BATCH_SIZE), train_y.split(BATCH_SIZE)):\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/5, Loss: {epoch_loss / len(train_x):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7937f218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'model.pth'.\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Model saved as 'model.pth'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34490bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 90.73%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in test_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        preds = model(batch_x)\n",
    "        pred_labels = torch.argmax(preds, dim=1)\n",
    "        correct += (pred_labels == batch_y).sum().item()\n",
    "        total += batch_y.size(0)\n",
    "\n",
    "print(f\"Validation Accuracy: {correct / total * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4beb2e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_video(video_path):\n",
    "    print(f\"\\nPredicting: {video_path}\")\n",
    "    frames = extract_frames_from_video(video_path)\n",
    "    if not frames:\n",
    "        print(\"No frames found.\")\n",
    "        return\n",
    "    model.eval()\n",
    "    results = []\n",
    "    for frame in frames[:10]:\n",
    "        img_tensor = transform(frame).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(img_tensor)\n",
    "            pred = torch.argmax(output, 1).item()\n",
    "            results.append(pred)\n",
    "    real_pct = results.count(0) / len(results) * 100\n",
    "    fake_pct = results.count(1) / len(results) * 100\n",
    "    print(f\"Real: {real_pct:.2f}%, Fake: {fake_pct:.2f}% => {'Real' if real_pct > fake_pct else 'Fake'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6090c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting: E:\\12345678\\test\\id3_id6_0001.mp4\n",
      "Real: 10.00%, Fake: 90.00% => Fake\n"
     ]
    }
   ],
   "source": [
    "predict_video(r\"E:\\12345678\\test\\id3_id6_0001.mp4\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa9f075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
